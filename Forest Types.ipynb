{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>b4</th>\n",
       "      <th>b5</th>\n",
       "      <th>b6</th>\n",
       "      <th>b7</th>\n",
       "      <th>b8</th>\n",
       "      <th>b9</th>\n",
       "      <th>...</th>\n",
       "      <th>pred_minus_obs_H_b9</th>\n",
       "      <th>pred_minus_obs_S_b1</th>\n",
       "      <th>pred_minus_obs_S_b2</th>\n",
       "      <th>pred_minus_obs_S_b3</th>\n",
       "      <th>pred_minus_obs_S_b4</th>\n",
       "      <th>pred_minus_obs_S_b5</th>\n",
       "      <th>pred_minus_obs_S_b6</th>\n",
       "      <th>pred_minus_obs_S_b7</th>\n",
       "      <th>pred_minus_obs_S_b8</th>\n",
       "      <th>pred_minus_obs_S_b9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d</td>\n",
       "      <td>39</td>\n",
       "      <td>36</td>\n",
       "      <td>57</td>\n",
       "      <td>91</td>\n",
       "      <td>59</td>\n",
       "      <td>101</td>\n",
       "      <td>93</td>\n",
       "      <td>27</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.36</td>\n",
       "      <td>-18.41</td>\n",
       "      <td>-1.88</td>\n",
       "      <td>-6.43</td>\n",
       "      <td>-21.03</td>\n",
       "      <td>-1.60</td>\n",
       "      <td>-6.18</td>\n",
       "      <td>-22.50</td>\n",
       "      <td>-5.20</td>\n",
       "      <td>-7.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>h</td>\n",
       "      <td>84</td>\n",
       "      <td>30</td>\n",
       "      <td>57</td>\n",
       "      <td>112</td>\n",
       "      <td>51</td>\n",
       "      <td>98</td>\n",
       "      <td>92</td>\n",
       "      <td>26</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.26</td>\n",
       "      <td>-16.27</td>\n",
       "      <td>-1.95</td>\n",
       "      <td>-6.25</td>\n",
       "      <td>-18.79</td>\n",
       "      <td>-1.99</td>\n",
       "      <td>-6.18</td>\n",
       "      <td>-23.41</td>\n",
       "      <td>-8.87</td>\n",
       "      <td>-10.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s</td>\n",
       "      <td>53</td>\n",
       "      <td>25</td>\n",
       "      <td>49</td>\n",
       "      <td>99</td>\n",
       "      <td>51</td>\n",
       "      <td>93</td>\n",
       "      <td>84</td>\n",
       "      <td>26</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.46</td>\n",
       "      <td>-15.92</td>\n",
       "      <td>-1.79</td>\n",
       "      <td>-4.64</td>\n",
       "      <td>-17.73</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>-4.69</td>\n",
       "      <td>-19.97</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>-7.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s</td>\n",
       "      <td>59</td>\n",
       "      <td>26</td>\n",
       "      <td>49</td>\n",
       "      <td>103</td>\n",
       "      <td>47</td>\n",
       "      <td>92</td>\n",
       "      <td>82</td>\n",
       "      <td>25</td>\n",
       "      <td>56</td>\n",
       "      <td>...</td>\n",
       "      <td>2.68</td>\n",
       "      <td>-13.77</td>\n",
       "      <td>-2.53</td>\n",
       "      <td>-6.34</td>\n",
       "      <td>-22.03</td>\n",
       "      <td>-2.34</td>\n",
       "      <td>-6.60</td>\n",
       "      <td>-27.10</td>\n",
       "      <td>-7.99</td>\n",
       "      <td>-10.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d</td>\n",
       "      <td>57</td>\n",
       "      <td>49</td>\n",
       "      <td>66</td>\n",
       "      <td>103</td>\n",
       "      <td>64</td>\n",
       "      <td>106</td>\n",
       "      <td>114</td>\n",
       "      <td>28</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.94</td>\n",
       "      <td>-21.74</td>\n",
       "      <td>-1.64</td>\n",
       "      <td>-4.62</td>\n",
       "      <td>-23.74</td>\n",
       "      <td>-0.85</td>\n",
       "      <td>-5.50</td>\n",
       "      <td>-22.83</td>\n",
       "      <td>-2.74</td>\n",
       "      <td>-5.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  class  b1  b2  b3   b4  b5   b6   b7  b8  b9         ...           \\\n",
       "0    d   39  36  57   91  59  101   93  27  60         ...            \n",
       "1    h   84  30  57  112  51   98   92  26  62         ...            \n",
       "2    s   53  25  49   99  51   93   84  26  58         ...            \n",
       "3    s   59  26  49  103  47   92   82  25  56         ...            \n",
       "4    d   57  49  66  103  64  106  114  28  59         ...            \n",
       "\n",
       "   pred_minus_obs_H_b9  pred_minus_obs_S_b1  pred_minus_obs_S_b2  \\\n",
       "0                -2.36               -18.41                -1.88   \n",
       "1                -2.26               -16.27                -1.95   \n",
       "2                -1.46               -15.92                -1.79   \n",
       "3                 2.68               -13.77                -2.53   \n",
       "4                -2.94               -21.74                -1.64   \n",
       "\n",
       "   pred_minus_obs_S_b3  pred_minus_obs_S_b4  pred_minus_obs_S_b5  \\\n",
       "0                -6.43               -21.03                -1.60   \n",
       "1                -6.25               -18.79                -1.99   \n",
       "2                -4.64               -17.73                -0.48   \n",
       "3                -6.34               -22.03                -2.34   \n",
       "4                -4.62               -23.74                -0.85   \n",
       "\n",
       "   pred_minus_obs_S_b6  pred_minus_obs_S_b7  pred_minus_obs_S_b8  \\\n",
       "0                -6.18               -22.50                -5.20   \n",
       "1                -6.18               -23.41                -8.87   \n",
       "2                -4.69               -19.97                -4.10   \n",
       "3                -6.60               -27.10                -7.99   \n",
       "4                -5.50               -22.83                -2.74   \n",
       "\n",
       "   pred_minus_obs_S_b9  \n",
       "0                -7.86  \n",
       "1               -10.83  \n",
       "2                -7.07  \n",
       "3               -10.81  \n",
       "4                -5.84  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path = 'all/ForestTypes/'\n",
    "file_nm = 'training.csv'\n",
    "file = pd.read_csv(path+file_nm)\n",
    "file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['d ' 39 36 ... -22.5 -5.2 -7.86]\n",
      " ['h ' 84 30 ... -23.41 -8.87 -10.83]\n",
      " ['s ' 53 25 ... -19.97 -4.1 -7.07]\n",
      " ...\n",
      " ['h ' 79 30 ... -23.32 -2.09 -4.13]\n",
      " ['h ' 69 27 ... -10.04 -0.74 -2.88]\n",
      " ['h ' 80 29 ... -20.91 -0.9 -3.7]]\n"
     ]
    }
   ],
   "source": [
    "data = file.values\n",
    "print (data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tree_node_class():\n",
    "    def __init__(self, content, true_branch=None, false_branch=None):\n",
    "        self.content  = content\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch\n",
    "    \n",
    "    def is_leaf(self):\n",
    "        return not (self.true_branch or self.false_branch)\n",
    "    \n",
    "class dtree_classification(object):\n",
    "    node = tree_node_class\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.root = None\n",
    "        self.size = 0\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_array_for_split(data, col_pos, label_pos):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    with_attr = np.array([row for row in data if not np.isnan(row[col_pos])])\n",
    "    missing_attr = np.array([row for row in data if np.isnan(row[col_pos])])\n",
    "    with_attr = with_attr[np.lexsort(np.fliplr(with_attr).T)]\n",
    "    \n",
    "    return with_attr, missing_attr\n",
    "\n",
    "def numeric_get_split(data, col, split_value):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    left = np.array([rw for rw in data if rw[col] <= split_value])\n",
    "    right = np.array([rw for rw in data if rw[col] > split_value])\n",
    "    return left, right\n",
    "\n",
    "# def discrete_get_split(data, attribute_set):\n",
    "#     \"\"\"\n",
    "#     \"\"\"\n",
    "#     for split_val in attribute_set:\n",
    "#         splits.append([rw[1] for rw in data if rw[0] == split_val])\n",
    "#     return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_entropy(groups, classes):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    entropy = 0\n",
    "    total_inst = sum([len(each_gr[0]) for each_gr in groups])\n",
    "\n",
    "    for each_gr in groups:\n",
    "        score = 0\n",
    "        \n",
    "        if len(each_gr) == 0:\n",
    "            continue\n",
    "            \n",
    "        label_col = each_gr[0]\n",
    "        weight_col = each_gr[1].astype(np.float)\n",
    "            \n",
    "        for each_cl in classes:\n",
    "            class_weight = [weight_col[i] \n",
    "                            for i in range(0, len(weight_col)) if label_col[i]==each_cl]\n",
    "            p = sum(class_weight) / sum(weight_col)\n",
    "            if p == 0:\n",
    "                continue\n",
    "            score += -p * np.log2(p)\n",
    "            \n",
    "        entropy += sum(weight_col) / total_inst * score\n",
    "    return entropy\n",
    "\n",
    "def calc_gini(groups, classes):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    gini = 0\n",
    "    total_inst = sum([len(each_gr[0]) for each_gr in groups])\n",
    "        \n",
    "    for each_gr in groups:\n",
    "        score = 0\n",
    "        \n",
    "        if len(each_gr[0]) == 0:\n",
    "            continue\n",
    "            \n",
    "        label_col = each_gr[0]\n",
    "        weight_col = each_gr[1].astype(np.float)\n",
    "\n",
    "        for each_cl in classes:\n",
    "            class_weight = [weight_col[i] \n",
    "                            for i in range(0, len(weight_col)) if label_col[i]==each_cl]\n",
    "            p = sum(class_weight) / sum(weight_col)\n",
    "            score += p * p\n",
    "            \n",
    "        gini += sum(weight_col) / total_inst * (1 - score)\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(198, 28)\n",
      "Column 2 (excl. label) <= 36.5\n",
      "Column 10 (excl. label) <= 41.735\n",
      "Column 22 (excl. label) <= -7.04\n",
      "Column 1 (excl. label) <= 79.0\n",
      "Column 1 (excl. label) <= 42.5\n",
      "Column 1 (excl. label) <= 39.5\n",
      "Column 13 (excl. label) <= -12.415\n",
      "Column 5 (excl. label) <= 49.5\n",
      "Column 8 (excl. label) <= 28.0\n",
      "Column 1 (excl. label) <= 51.5\n",
      "Column 7 (excl. label) <= 74.0\n",
      "Tree\n",
      "[['h ' 84 30 ... -23.41 -8.87 -10.83]\n",
      " ['h ' 85 28 ... -29.72 -1.94 -4.94]\n",
      " ['h ' 74 29 ... -17.2 -1.27 -5.42]\n",
      " ...\n",
      " ['h ' 79 30 ... -23.32 -2.09 -4.13]\n",
      " ['h ' 69 27 ... -10.04 -0.74 -2.88]\n",
      " ['h ' 80 29 ... -20.91 -0.9 -3.7]]\n",
      "(22, -7.04)\n",
      "[['h ' 67 31 55 102 47 89 81 23 56 36.04 16.24 34.0 -21.83 -23.89 -34.25\n",
      "  -13.77 5.9 -2.28 -8.26 0.54 -1.29 -3.51 0.51 -0.59 -6.17 -0.81 -2.1]\n",
      " ['h ' 78 30 56 107 50 93 84 24 57 28.5 19.5 36.5 -23.34 -24.99 -35.98\n",
      "  -6.17 6.02 -1.04 -12.8 0.84 -2.32 -6.14 -0.41 -1.18 -18.9 0.64 -3.3]]\n",
      "(1, 79.0)\n",
      "[['s ' 80 29 54 119 50 95 101 24 60 33.33 22.28 42.05 -19.36 -24.69\n",
      "  -35.02 -25.24 6.32 -3.92 5.13 -1.35 -1.41 1.88 -0.53 -0.94 3.67 -1.26\n",
      "  -1.35]]\n",
      "(10, 41.735)\n",
      "[['d ' 39 36 57 91 59 101 93 27 60 75.7 14.86 40.35 7.97 -32.92 -38.92\n",
      "  -14.94 4.47 -2.36 -18.41 -1.88 -6.43 -21.03 -1.6 -6.18 -22.5 -5.2 -7.86]\n",
      " ['d ' 34 32 53 97 53 97 59 22 50 83.32 19.34 45.03 4.09 -26.76 -33.99\n",
      "  20.34 7.06 5.3 -22.93 -1.82 -5.44 -27.3 -1.37 -6.44 -23.23 -1.89 -4.89]]\n",
      "(1, 39.5)\n",
      "[['s ' 40 25 47 81 49 87 74 24 55 69.79 24.89 45.49 13.05 -23.97 -28.46\n",
      "  0.32 5.44 -0.46 -28.43 -1.28 -5.49 -25.56 -1.42 -5.88 -27.55 -2.63\n",
      "  -5.26]]\n",
      "(1, 42.5)\n",
      "[['h ' 56 26 51 107 49 91 78 23 55 51.23 22.69 42.15 -29.06 -25.75 -35.68\n",
      "  -19.37 3.39 -3.74 -17.84 0.77 -2.66 -10.48 0.44 -0.97 -6.78 0.48 -0.72]\n",
      " ['h ' 70 29 54 114 47 89 98 25 58 45.73 18.0 36.15 -16.48 -22.26 -31.1\n",
      "  -18.38 3.84 -3.31 -21.74 0.95 -2.44 -21.3 -1.11 -3.8 -19.31 -0.56 -2.94]]\n",
      "(5, 49.5)\n",
      "[['s ' 70 28 54 113 52 100 88 25 63 44.55 22.46 43.37 -17.31 -26.17\n",
      "  -38.22 -12.66 3.85 -8.02 -4.81 0.97 2.27 -8.54 -0.2 -0.04 -7.13 -0.3\n",
      "  -0.14]]\n",
      "(13, -12.415)\n",
      "[['s ' 53 25 ... -19.97 -4.1 -7.07]\n",
      " ['s ' 59 26 ... -27.1 -7.99 -10.81]\n",
      " ['s ' 56 29 ... -23.17 -0.22 -4.22]\n",
      " ...\n",
      " ['s ' 62 28 ... -11.45 -1.57 -4.16]\n",
      " ['s ' 56 27 ... -28.6 -2.97 -5.27]\n",
      " ['s ' 58 25 ... -14.66 -2.17 -4.37]]\n",
      "(2, 36.5)\n",
      "[['d ' 57 49 ... -22.83 -2.74 -5.84]\n",
      " ['d ' 40 39 ... -21.16 -3.42 -6.61]\n",
      " ['d ' 51 47 ... -24.11 -1.67 -5.04]\n",
      " ...\n",
      " ['d ' 58 62 ... -10.08 -1.78 -3.64]\n",
      " ['d ' 55 61 ... -17.81 -1.28 -3.87]\n",
      " ['d ' 66 69 ... -16.77 -1.46 -4.03]]\n",
      "(8, 28.0)\n",
      "[['d ' 51 53 72 88 74 111 64 39 67 61.26 -1.41 23.57 11.49 -48.59 -51.07\n",
      "  11.6 -8.03 -10.57 -17.89 -0.82 -1.82 -21.4 -0.66 -3.75 -19.55 -3.05\n",
      "  -5.48]]\n",
      "(7, 74.0)\n",
      "[['o ' 51 57 77 90 89 123 97 47 83 64.91 -5.21 21.45 12.21 -62.9 -60.4\n",
      "  -16.75 -16.85 -26.44 -20.97 -1.76 -5.05 -22.01 -0.93 -5.6 -22.26 -3.28\n",
      "  -6.39]\n",
      " ['o ' 41 44 67 64 71 104 84 54 85 71.81 8.35 34.35 33.13 -44.66 -40.47\n",
      "  -7.91 -24.34 -28.44 -18.06 -3.04 -10.02 -18.23 -1.68 -7.48 -19.16 -2.55\n",
      "  -6.17]\n",
      " ['o ' 45 43 62 96 63 101 90 30 65 63.77 6.03 31.53 -7.27 -38.71 -43.91\n",
      "  -23.74 -1.89 -11.44 -16.33 0.63 -2.7 -17.18 -0.2 -1.83 -11.33 -0.95\n",
      "  -2.64]]\n",
      "(1, 51.5)\n",
      "[['o ' 75 68 89 116 77 118 94 42 76 43.28 -16.52 9.17 -13.26 -50.8 -54.87\n",
      "  -13.2 -12.88 -20.64 -24.49 -1.42 -4.34 -27.33 -0.91 -5.92 -24.1 -1.21\n",
      "  -4.88]\n",
      " ['o ' 64 52 71 98 72 109 87 37 70 50.02 -0.56 27.64 0.31 -46.02 -46.84\n",
      "  -9.36 -5.94 -12.59 -18.32 -2.47 -7.93 -20.07 -1.51 -6.34 -21.78 -4.52\n",
      "  -7.42]\n",
      " ['o ' 67 68 89 108 74 114 117 44 86 44.82 -17.32 8.65 -14.46 -46.89\n",
      "  -50.18 -42.21 -14.5 -29.84 -20.1 -0.05 -3.1 -20.06 -1.11 -4.97 -18.07\n",
      "  -0.29 -3.91]\n",
      " ['o ' 78 85 101 124 82 126 91 50 80 37.23 -33.92 -3.44 -24.21 -55.89\n",
      "  -63.47 -13.53 -20.94 -24.71 -20.68 -1.6 -5.22 -24.8 -1.16 -5.72 -20.59\n",
      "  -1.67 -4.54]\n",
      " ['o ' 66 78 101 106 73 114 112 36 73 48.08 -26.47 -2.61 -7.11 -47.11\n",
      "  -52.05 -33.92 -5.12 -15.77 -19.12 -2.7 -8.21 -19.17 -1.41 -6.24 -20.34\n",
      "  -3.67 -6.73]\n",
      " ['o ' 67 75 95 92 84 120 81 53 86 44.85 -24.28 2.59 3.77 -57.73 -57.22\n",
      "  -7.92 -24.11 -30.97 -15.64 -0.66 -2.3 -17.71 -0.63 -4.03 -13.26 -0.37\n",
      "  -2.91]\n",
      " ['o ' 63 70 92 90 87 129 103 70 109 49.2 -19.21 5.67 4.24 -60.53 -66.15\n",
      "  -28.98 -40.84 -53.53 -18.39 -0.31 -2.56 -19.41 -0.83 -4.3 -16.09 -0.47\n",
      "  -3.3]\n",
      " ['o ' 60 62 85 101 73 115 96 37 73 52.89 -11.6 10.43 -2.35 -47.73 -54.87\n",
      "  -21.37 -7.74 -17.87 -17.73 -0.76 -3.36 -23.32 -0.69 -3.76 -17.22 -1.81\n",
      "  -4.13]\n",
      " ['o ' 52 49 67 54 53 87 62 52 79 60.6 0.08 25.76 40.82 -28.08 -28.07\n",
      "  14.3 -22.3 -23.61 -19.63 -1.72 -5.0 -18.12 -1.28 -4.96 -16.85 -1.57\n",
      "  -4.05]\n",
      " ['o ' 61 59 77 99 73 111 105 35 73 52.61 -8.27 20.31 -5.01 -47.45 -50.12\n",
      "  -31.09 -6.15 -18.15 -19.07 -0.19 -2.64 -20.29 -0.49 -3.32 -16.19 -0.65\n",
      "  -3.04]\n",
      " ['o ' 56 69 91 93 96 136 74 54 90 59.92 -17.71 5.0 9.94 -70.58 -75.28\n",
      "  5.65 -23.42 -33.37 -20.87 -1.07 -4.62 -23.83 -0.66 -4.56 -20.6 -2.14\n",
      "  -4.74]\n",
      " ['o ' 55 58 81 97 77 121 85 38 71 56.46 -7.94 14.45 -5.31 -51.94 -61.81\n",
      "  -13.99 -9.3 -16.49 -16.3 -0.04 -2.15 -16.69 -0.43 -2.48 -13.21 -0.98\n",
      "  -3.09]\n",
      " ['o ' 92 56 83 172 58 110 97 82 108 20.01 -7.05 9.35 -77.01 -33.18\n",
      "  -51.38 -21.07 -52.0 -52.4 -19.16 -0.82 -4.46 -18.93 -1.08 -4.44 -16.63\n",
      "  -1.5 -3.74]\n",
      " ['o ' 68 76 89 111 82 123 121 35 74 44.09 -25.64 7.07 -18.54 -56.8\n",
      "  -63.39 -49.08 -6.17 -19.31 -16.76 -0.27 -2.29 -17.49 -0.54 -2.75 -14.02\n",
      "  -1.07 -3.24]\n",
      " ['o ' 63 53 74 98 77 113 77 39 68 51.01 -1.64 21.35 3.4 -51.68 -52.8\n",
      "  0.55 -8.36 -11.49 -17.77 -1.08 -3.27 -22.03 -0.7 -4.09 -17.92 -2.13\n",
      "  -4.52]\n",
      " ['o ' 61 67 90 93 92 131 85 56 96 52.6 -15.13 8.69 0.39 -66.51 -70.45\n",
      "  -10.4 -26.99 -41.04 -20.0 -0.72 -2.33 -20.65 -0.46 -3.13 -16.9 -0.73\n",
      "  -3.04]\n",
      " ['o ' 98 89 107 152 67 115 114 46 85 15.14 -37.5 -12.28 -51.16 -41.72\n",
      "  -55.12 -37.02 -14.94 -28.14 -18.38 -1.78 -4.85 -22.4 -0.94 -4.61 -18.01\n",
      "  -2.31 -4.97]\n",
      " ['o ' 71 65 85 100 81 121 120 35 73 41.86 -13.07 13.72 -7.37 -55.67\n",
      "  -60.87 -45.74 -6.05 -18.19 -19.74 -1.1 -3.55 -20.74 -0.64 -3.31 -17.51\n",
      "  -1.09 -3.32]\n",
      " ['o ' 81 98 125 117 90 129 89 46 76 28.79 -50.31 -34.91 -25.59 -65.59\n",
      "  -71.75 -14.35 -16.71 -21.35 -16.7 0.26 -2.5 -15.87 -0.79 -3.25 -14.96\n",
      "  -0.71 -2.72]\n",
      " ['o ' 61 65 83 144 58 110 139 38 76 52.32 -13.22 13.44 -44.13 -32.56\n",
      "  -49.8 -62.74 -7.4 -19.77 -15.81 -1.77 -2.89 -20.61 -1.02 -4.11 -16.34\n",
      "  -2.58 -4.78]\n",
      " ['o ' 105 160 196 131 65 109 96 40 75 7.66 -112.6 -106.12 -38.71 -40.47\n",
      "  -51.39 -19.3 -10.79 -20.43 -25.7 0.7 -3.87 -22.34 -1.05 -4.52 -20.14\n",
      "  2.24 -0.53]\n",
      " ['o ' 62 65 90 97 85 126 92 47 83 52.44 -12.71 9.16 -2.96 -59.82 -66.06\n",
      "  -17.38 -17.95 -28.17 -19.07 -1.45 -4.35 -18.69 -0.58 -3.21 -16.36 -1.17\n",
      "  -3.39]\n",
      " ['o ' 63 71 95 100 87 130 79 43 77 52.16 -18.5 4.5 -4.83 -61.78 -69.99\n",
      "  -3.44 -13.77 -21.94 -19.55 -1.78 -4.91 -19.38 -0.6 -3.39 -17.04 -1.36\n",
      "  -3.63]\n",
      " ['o ' 63 68 87 115 75 120 92 42 76 51.09 -16.18 10.95 -17.15 -49.64\n",
      "  -59.83 -16.63 -11.81 -20.05 -16.8 -1.61 -3.96 -19.47 -0.89 -3.82 -15.76\n",
      "  -2.4 -4.61]\n",
      " ['o ' 52 59 88 95 97 136 63 55 80 63.49 -6.16 11.9 0.18 -71.86 -76.09\n",
      "  13.49 -25.72 -24.92 -20.18 -1.11 -4.22 -18.82 -0.56 -3.14 -17.77 -1.37\n",
      "  -3.61]\n",
      " ['o ' 60 46 73 114 69 116 92 29 63 55.13 6.6 26.39 -19.22 -43.95 -56.32\n",
      "  -15.33 0.09 -8.1 -21.34 -0.46 -3.55 -20.09 -0.56 -3.17 -19.49 -1.32\n",
      "  -3.74]\n",
      " ['o ' 58 58 76 109 80 121 64 48 70 59.55 -4.03 25.95 -11.91 -54.61\n",
      "  -60.54 13.63 -18.2 -14.35 -22.27 -2.19 -6.03 -19.7 -0.9 -3.99 -19.17\n",
      "  -1.93 -4.48]\n",
      " ['o ' 53 67 97 76 88 130 54 56 92 64.01 -14.03 2.69 20.05 -63.04 -70.47\n",
      "  24.33 -27.03 -37.12 -22.74 0.14 -2.32 -20.47 -0.54 -3.14 -20.83 -1.13\n",
      "  -3.84]\n",
      " ['o ' 67 48 68 110 72 115 81 34 66 51.87 5.77 33.27 -11.84 -46.93 -54.94\n",
      "  -0.7 -5.02 -10.97 -23.25 0.65 -1.84 -19.67 -0.48 -3.16 -21.6 -0.63\n",
      "  -3.77]\n",
      " ['o ' 74 40 61 110 66 110 111 29 68 45.06 14.11 40.33 -11.05 -40.91\n",
      "  -50.03 -30.16 0.21 -12.73 -23.93 0.49 -2.37 -20.46 -0.52 -3.26 -22.27\n",
      "  -0.89 -4.06]\n",
      " ['o ' 72 77 92 98 98 125 96 39 70 41.46 -28.91 1.47 -2.01 -73.29 -65.54\n",
      "  -17.56 -9.56 -14.62 -22.7 -1.8 -6.67 -20.66 -1.37 -5.89 -20.25 -1.43\n",
      "  -4.22]\n",
      " ['o ' 59 67 81 85 81 114 86 38 68 53.11 -18.74 12.34 10.15 -56.22 -54.7\n",
      "  -9.19 -8.43 -12.76 -21.3 -1.83 -6.49 -18.61 -1.32 -5.49 -18.37 -1.65\n",
      "  -4.16]\n",
      " ['o ' 69 72 94 90 79 120 79 43 72 43.71 -22.33 0.06 9.54 -54.27 -60.89\n",
      "  -3.23 -13.67 -17.18 -21.29 -0.48 -4.03 -28.07 -1.29 -6.06 -19.32 -0.67\n",
      "  -3.45]\n",
      " ['o ' 55 58 76 89 84 118 83 36 69 62.31 -5.84 22.37 13.68 -59.12 -58.43\n",
      "  -2.94 -6.73 -13.94 -23.2 -0.1 -3.45 -27.1 -1.0 -4.68 -22.83 -1.41 -4.02]]\n",
      "198\n"
     ]
    }
   ],
   "source": [
    "# dataset = [[2.771244718, 1.784783929, 0], \n",
    "#            [1.728571309, 1.169761413, 0], \n",
    "#            [3.678319846, 2.81281357, 0], \n",
    "#            [3.961043357, 2.61995032, 0], \n",
    "#            [2.999208922, 2.209014212, 0], \n",
    "#            [7.497545867, 3.162953546, 1], \n",
    "#            [9.00220326, 3.339047188, 1], \n",
    "#            [7.444542326, 0.476683375, 1], \n",
    "#            [10.12493903, 3.234550982, 1], \n",
    "#            [6.642287351, 3.319983761, 1]]\n",
    "\n",
    "def add_weight(groups, label_pos):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    splits = []\n",
    "\n",
    "    for each_gr in groups:\n",
    "        label = [row[label_pos] for row in each_gr]\n",
    "        with_weight = np.vstack((label, np.ones(len(each_gr))))\n",
    "        splits.append(with_weight)\n",
    "\n",
    "    return splits\n",
    "\n",
    "def redistribute_missing(with_attr_grps, without_attr_grp):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    splits = []\n",
    "    total_no_miss = sum([len(each) for each in with_attr_grps])\n",
    "\n",
    "    for each_gr in with_attr_grps:\n",
    "        if len(without_attr_grp) != 0:\n",
    "            prob_weight = (len(each_gr) / total_no_miss) * np.ones(len(without_attr_grp))\n",
    "            frac_attr = np.vstack((without_attr_grp, prob_weight))\n",
    "            each_gr.append(frac_attr)\n",
    "            \n",
    "        splits.append(each_gr)\n",
    "\n",
    "    return splits\n",
    "\n",
    "def find_best_split(dataset, label_pos, homogeneity_measure='gini'):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    col_num = dataset.shape[1]\n",
    "    \n",
    "    if homogeneity_measure == 'entropy':\n",
    "        weighted_label = add_weight([dataset], label_pos)\n",
    "        total_entropy = calc_entropy([weighted_label], class_list)\n",
    "    \n",
    "    split = ()\n",
    "    best_hg = 1\n",
    "    for c in range(0, col_num):\n",
    "        if c == label_pos:\n",
    "            continue\n",
    "        with_attr, _ = prepare_array_for_split(dataset, c, label_pos)\n",
    "\n",
    "        if dataset_meta[c] == 'num':\n",
    "            for r in range(1, len(with_attr)):\n",
    "                split_val = (with_attr[r-1, c] + with_attr[r, c]) / 2\n",
    "                left, right = numeric_get_split(with_attr, c, split_val)\n",
    "                weighted_label_split = add_weight([left, right], label_pos)\n",
    "\n",
    "                if homogeneity_measure == 'entropy':\n",
    "                    info_gain = total_entropy - calc_entropy(weighted_label_split, class_list)\n",
    "                    new_hg = info_gain\n",
    "\n",
    "                    if new_hg > best_hg:\n",
    "                        best_hg = new_hg\n",
    "                        split = (c, split_val)\n",
    "                else:\n",
    "                    new_hg = calc_gini(weighted_label_split, class_list)\n",
    "\n",
    "                    if new_hg < best_hg:\n",
    "                        best_hg = new_hg\n",
    "                        split = (c, split_val)\n",
    "                        \n",
    "#         else:\n",
    "#             col_attr_set = list(set([row[0] for row in split_col]))\n",
    "#             splits = discrete_get_split(split_col, col_attr_set)\n",
    "            \n",
    "#             if homogeneity_measure == 'entropy':\n",
    "#                 info_gain = total_entropy - calc_entropy(splits, class_list)\n",
    "#                 intrinsic_info = \n",
    "#             else:\n",
    "\n",
    "    return split, best_hg\n",
    "\n",
    "def construct_tree(root, data, min_leaf_size, homogeneity_measure='gini'):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    split_loc, score = find_best_split(data, label_pos, homogeneity_measure)\n",
    "    left, right = numeric_get_split(data, split_loc[0], split_loc[1])\n",
    "\n",
    "    if homogeneity_measure == 'entropy':\n",
    "        pass\n",
    "    else:\n",
    "        left_hg = calc_gini(add_weight([left], label_pos), class_list)\n",
    "        right_hg = calc_gini(add_weight([right], label_pos), class_list)\n",
    "        min_hg = 0\n",
    "    \n",
    "    expression = 'Column ' + str(split_loc[0]) + ' (excl. label) <= ' + str(split_loc[1])\n",
    "    print (expression)\n",
    "\n",
    "    if len(root.content) == 0:\n",
    "        root = tree_node_class(content=split_loc)\n",
    "        \n",
    "    if (len(left) <= min_leaf_size) or (left_hg == min_hg):\n",
    "        root.true_branch = tree_node_class(content=left)\n",
    "    else:\n",
    "        root.true_branch = tree_node_class([])\n",
    "        root.true_branch = construct_tree(root.true_branch, left, min_leaf_size)\n",
    "\n",
    "    if (len(right) <= min_leaf_size) or (right_hg == min_hg):\n",
    "        root.false_branch = tree_node_class(content=right)\n",
    "    else:\n",
    "        root.false_branch = tree_node_class([])\n",
    "        root.false_branch = construct_tree(root.false_branch, right, min_leaf_size)\n",
    "        \n",
    "    return root\n",
    "\n",
    "def print_tree(tree_root):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    global leaf_size_tot\n",
    "    if tree_root is None:\n",
    "        return\n",
    "    print_tree(tree_root.true_branch)    \n",
    "    print (tree_root.content)\n",
    "    if tree_root.is_leaf():\n",
    "        leaf_size_tot += len(tree_root.content)\n",
    "    print_tree(tree_root.false_branch)\n",
    "\n",
    "dataset = np.array(data)\n",
    "print (dataset.shape)\n",
    "\n",
    "label_pos = 0\n",
    "min_leaf_size = 1\n",
    "\n",
    "label_val = [row[label_pos] for row in dataset]\n",
    "class_list = list(set(label_val))\n",
    "\n",
    "dataset_meta = ['disc'] + ['num' for i in range(dataset.shape[1])]\n",
    "\n",
    "r = tree_node_class([])\n",
    "tree = construct_tree(r, dataset, min_leaf_size)\n",
    "\n",
    "leaf_size_tot = 0\n",
    "print ('Tree')\n",
    "print_tree(tree)\n",
    "print (leaf_size_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(325, 28)\n",
      "[['d ' 67 51 ... -22.56 -5.53 -8.11]\n",
      " ['s ' 67 28 ... -22.2 -3.41 -6.57]\n",
      " ['s ' 63 26 ... -20.89 -3.96 -6.85]\n",
      " ...\n",
      " ['s ' 49 26 ... -24.5 -2.53 -4.97]\n",
      " ['s ' 55 26 ... -24.39 -2.21 -4.72]\n",
      " ['h ' 71 28 ... -12.74 -1.36 -3.63]]\n"
     ]
    }
   ],
   "source": [
    "file1_nm = 'testing.csv'\n",
    "content = pd.read_csv(path+file1_nm)\n",
    "content = content.values\n",
    "print (content.shape)\n",
    "print (content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['o ', 's ', 's ', 'd ', 's ', 'o ', 'h ', 'd ', 'h ', 'd ', 's ', 'o ', 's ', 'h ', 'o ', 's ', 'o ', 'd ', 's ', 'd ', 'o ', 's ', 'd ', 's ', 's ', 's ', 's ', 's ', 's ', 'd ', 's ', 'o ', 's ', 's ', 'o ', 'd ', 'o ', 'd ', 's ', 'o ', 'd ', 'h ', 'o ', 'o ', 's ', 'o ', 's ', 's ', 'h ', 's ', 'o ', 'o ', 'h ', 'h ', 'd ', 's ', 'h ', 'o ', 's ', 's ', 's ', 'd ', 's ', 's ', 's ', 's ', 'd ', 'd ', 'd ', 's ', 's ', 'd ', 'o ', 's ', 'h ', 's ', 's ', 's ', 's ', 's ', 'd ', 's ', 's ', 'h ', 'd ', 's ', 's ', 'o ', 'd ', 's ', 'o ', 'd ', 's ', 's ', 's ', 'd ', 'd ', 's ', 'd ', 'd ', 's ', 'h ', 's ', 's ', 's ', 's ', 'o ', 'o ', 'o ', 's ', 'o ', 's ', 'o ', 's ', 's ', 'o ', 'o ', 's ', 's ', 'h ', 'd ', 'h ', 'd ', 's ', 's ', 's ', 'd ', 's ', 'd ', 'o ', 'd ', 'd ', 's ', 's ', 'd ', 's ', 'o ', 'd ', 's ', 's ', 'd ', 'd ', 's ', 'o ', 's ', 'd ', 's ', 'd ', 's ', 'h ', 'h ', 'd ', 'o ', 'd ', 'o ', 'd ', 'o ', 'd ', 'h ', 'd ', 's ', 'd ', 'd ', 's ', 's ', 's ', 'd ', 'o ', 's ', 's ', 's ', 'o ', 'd ', 's ', 's ', 'h ', 'd ', 's ', 'd ', 'd ', 'd ', 'd ', 's ', 'd ', 'd ', 's ', 'd ', 'o ', 'd ', 's ', 'o ', 's ', 's ', 'h ', 'd ', 'o ', 'h ', 's ', 'd ', 'h ', 's ', 'd ', 'd ', 's ', 's ', 's ', 'd ', 's ', 's ', 's ', 'o ', 'o ', 'd ', 'd ', 'd ', 'o ', 'h ', 's ', 'd ', 's ', 's ', 'd ', 's ', 'h ', 's ', 'd ', 's ', 's ', 'd ', 's ', 's ', 'o ', 's ', 's ', 'd ', 'd ', 's ', 'o ', 'd ', 'd ', 'o ', 'o ', 'd ', 's ', 'o ', 's ', 's ', 'd ', 's ', 's ', 's ', 'd ', 's ', 'd ', 'd ', 'd ', 's ', 'd ', 's ', 's ', 's ', 'd ', 's ', 's ', 's ', 's ', 's ', 's ', 'o ', 's ', 'o ', 's ', 's ', 's ', 's ', 's ', 's ', 'd ', 'd ', 'o ', 'd ', 'o ', 'h ', 'd ', 'h ', 'd ', 's ', 'h ', 's ', 's ', 'h ', 'd ', 's ', 's ', 'h ', 's ', 's ', 's ', 's ', 'd ', 's ', 's ', 's ', 'h ', 's ', 's ', 'o ', 's ', 's ', 'h ', 's ', 's ', 's ', 's ', 's ', 'h ', 's ', 's ', 's ', 'd ', 'o ', 'd ', 's ', 's ', 'h ']\n",
      "Accuracy 80.3076923076923\n"
     ]
    }
   ],
   "source": [
    "def classify_from_tree(dtree, predict_cases, label_pos):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    output = []\n",
    "    for case in predict_cases:\n",
    "        case_tree = dtree\n",
    "        while not case_tree.is_leaf():\n",
    "            col_test, test = case_tree.content\n",
    "            \n",
    "            if case[col_test] <= test:\n",
    "                case_tree = case_tree.true_branch\n",
    "            else:\n",
    "                case_tree = case_tree.false_branch\n",
    "        \n",
    "        label = [row[label_pos] for row in case_tree.content]\n",
    "        most_common_value = max(map(lambda x: (x, label.count(x)), set(label)))[0]\n",
    "        output.append(most_common_value)\n",
    "    return output\n",
    "\n",
    "classification = classify_from_tree(tree, content, label_pos)\n",
    "print (classification)\n",
    "true_label = [row[label_pos] for row in content]\n",
    "diff = [predict == label for predict, label in zip(classification, true_label)]\n",
    "acc = sum(diff) / content.shape[0] * 100\n",
    "print ('Accuracy {}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
